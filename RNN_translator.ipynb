{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a907188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 13:24:45.516173: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee00434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbc54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved splitted data\n",
    "train_pairs = pickle.load(open(\"data/train_pairs.pkl\", \"rb\"))\n",
    "val_pairs = pickle.load(open(\"data/val_pairs.pkl\", \"rb\"))\n",
    "test_pairs = pickle.load(open(\"data/test_pairs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d201c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output vocabulary:\n",
      "['', '[UNK]', 'd', 'a', 'c', 'b', 'f', 'g', 'e', 'h', 'j', 'i', '[start]', '[end]', 'k', 'l', 'm', 'ed', 'ee', 'ef', 'eg', 'eh']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 13:24:48.553751: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load vectorization for output language\n",
    "from_disk = pickle.load(open(\"model/target_vectorization8.pkl\", \"rb\"))\n",
    "target_vectorization = layers.TextVectorization.from_config(from_disk['config'])\n",
    "\n",
    "target_vectorization.set_weights(from_disk['weights'])\n",
    "\n",
    "\n",
    "print(f\"output vocabulary:\\n{target_vectorization.get_vocabulary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f292d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary:\n",
      "['', '[UNK]', 'a', 'd', 'c', 'b', 'f', 'g', 'e', 'h']\n"
     ]
    }
   ],
   "source": [
    "# load vectorization for input language\n",
    "from_disk = pickle.load(open(\"model/source_vectorization8.pkl\", \"rb\"))\n",
    "source_vectorization = layers.TextVectorization.from_config(from_disk['config'])\n",
    "\n",
    "source_vectorization.set_weights(from_disk['weights'])\n",
    "\n",
    "\n",
    "print(f\"input vocabulary:\\n{source_vectorization.get_vocabulary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bb80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions based on the dataset analysis\n",
    "input_vocab_size = 8 + 2  # +2 for \"\" and Unkown\n",
    "\n",
    "# max text length in both input and output text is 47\n",
    "# but I increased to 55 to account for longer texts that may exist in unseen data\n",
    "output_seq_len = 55\n",
    "input_seq_len = output_seq_len\n",
    "output_vocab_size = 18 + 2 + 2  # +2 for \"\" and Unkown and +2 for [start] and [end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddbc8d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df9c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdc854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(source, target):\n",
    "    source = source_vectorization(source)\n",
    "    target = target_vectorization(target)\n",
    "    return (\n",
    "    {\n",
    "        \"source\": source,\n",
    "        \"translated\": target[:, :-1]\n",
    "        \n",
    "    }, target[:, 1:])\n",
    "\n",
    "def make_dataset(source_target_pairs, **kwargs):\n",
    "    batch_size = kwargs.get(\"batch_size\", 64)\n",
    "    source_texts, target_texts = zip(*source_target_pairs)\n",
    "    source_texts = list(source_texts)\n",
    "    target_texts = list(target_texts)\n",
    "    # source and target data will be stored in tf dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((source_texts, target_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # apply data preprocessing function as in the order they stored in tf dataset\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30c5b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_pairs, batch_size=batch_size)\n",
    "val_ds = make_dataset(val_pairs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a49a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs source shape: (128, 55)\n",
      "inputs translated shape: (128, 55)\n",
      "target shape: (128, 55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 09:57:48.108336: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# debugging purpose\n",
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs source shape: {inputs['source'].shape}\")\n",
    "    print(f\"inputs translated shape: {inputs['translated'].shape}\")\n",
    "    print(f\"target shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa28d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary:\n",
      "['', '[UNK]', 'a', 'd', 'c', 'b', 'f', 'g', 'e', 'h']\n",
      "output vocabulary:\n",
      "['', '[UNK]', 'd', 'a', 'c', 'b', 'f', 'g', 'e', 'h', 'j', 'i', '[start]', '[end]', 'k', 'l', 'm', 'ed', 'ee', 'ef', 'eg', 'eh']\n"
     ]
    }
   ],
   "source": [
    "in_vocab = source_vectorization.get_vocabulary()\n",
    "out_vocab = target_vectorization.get_vocabulary()\n",
    "print(f\"input vocabulary:\\n{in_vocab}\")\n",
    "print(f\"output vocabulary:\\n{out_vocab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d48d8d",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17b98d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension for Transformer\n",
    "embed_dim = 16\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dbae4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " source (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " translated (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, None, 16)     880         ['source[0][0]']                 \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, None, 16)     880         ['translated[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 256)         420864      ['embedding_6[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " gru_7 (GRU)                    (None, None, 256)    210432      ['embedding_7[0][0]',            \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, None, 256)    0           ['gru_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, None, 22)     5654        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 638,710\n",
      "Trainable params: 638,710\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder architecture\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")  # source language input\n",
    "# embedding layer\n",
    "x = layers.Embedding(input_dim=input_seq_len, output_dim=embed_dim, mask_zero=True)(encoder_inputs)\n",
    "# bidirectional RNN layer\n",
    "encoder_outputs = layers.Bidirectional(layers.GRU(latent_dim), merge_mode=\"sum\")(x)\n",
    "\n",
    "# decoder architecture\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"translated\")  # target language input\n",
    "# embedding layer\n",
    "x = layers.Embedding(input_dim=output_seq_len, output_dim=embed_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "#output = layers.Dense(output_vocab_size, activation=\"softmax\")(x)\n",
    "output = layers.Dense(output_vocab_size)(x)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df28ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    # loss fucntion for machine translation(Cross entropy modified to account for masking)\n",
    "    mask = label != 0\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = loss_function(label, pred)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask  # no loss computed for a token that is masked in a sequence\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)  # averaged by the number of non-mask tokens\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    # model accuracy computation accounting for masking\n",
    "    pred = tf.argmax(pred, axis=-1)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    accurate = label == pred  # boolean tensor True if predicted correctly\n",
    "    mask = label != 0\n",
    "    accurate = accurate & mask  # mark as accurate if correctly predicted and not masked token\n",
    "    accurate = tf.cast(accurate, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accurate) / tf.reduce_sum(mask)  # averaged by the number of non-mask tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d43a9116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "613/613 [==============================] - 167s 264ms/step - loss: 0.8167 - masked_accuracy: 0.4884 - val_loss: 0.4772 - val_masked_accuracy: 0.6792 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "613/613 [==============================] - 160s 260ms/step - loss: 0.4386 - masked_accuracy: 0.6983 - val_loss: 0.3439 - val_masked_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "613/613 [==============================] - 160s 261ms/step - loss: 0.3260 - masked_accuracy: 0.7727 - val_loss: 0.2754 - val_masked_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "613/613 [==============================] - 160s 261ms/step - loss: 0.2570 - masked_accuracy: 0.8179 - val_loss: 0.2088 - val_masked_accuracy: 0.8487 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "613/613 [==============================] - 160s 260ms/step - loss: 0.2082 - masked_accuracy: 0.8493 - val_loss: 0.1695 - val_masked_accuracy: 0.8732 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "613/613 [==============================] - 160s 261ms/step - loss: 0.1735 - masked_accuracy: 0.8727 - val_loss: 0.1655 - val_masked_accuracy: 0.8795 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "613/613 [==============================] - 159s 260ms/step - loss: 0.1472 - masked_accuracy: 0.8910 - val_loss: 0.1140 - val_masked_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "613/613 [==============================] - 159s 260ms/step - loss: 0.1286 - masked_accuracy: 0.9038 - val_loss: 0.1578 - val_masked_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "613/613 [==============================] - 159s 260ms/step - loss: 0.1137 - masked_accuracy: 0.9141 - val_loss: 0.0899 - val_masked_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "613/613 [==============================] - 159s 260ms/step - loss: 0.1020 - masked_accuracy: 0.9229 - val_loss: 0.0788 - val_masked_accuracy: 0.9386 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "613/613 [==============================] - 159s 260ms/step - loss: 0.0904 - masked_accuracy: 0.9343 - val_loss: 0.0796 - val_masked_accuracy: 0.9427 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "613/613 [==============================] - 159s 260ms/step - loss: 0.0762 - masked_accuracy: 0.9484 - val_loss: 0.0878 - val_masked_accuracy: 0.9456 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "613/613 [==============================] - 159s 259ms/step - loss: 0.0631 - masked_accuracy: 0.9595 - val_loss: 0.0423 - val_masked_accuracy: 0.9733 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "613/613 [==============================] - 159s 260ms/step - loss: 0.0530 - masked_accuracy: 0.9671 - val_loss: 0.0326 - val_masked_accuracy: 0.9795 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "613/613 [==============================] - 159s 259ms/step - loss: 0.0452 - masked_accuracy: 0.9728 - val_loss: 0.0316 - val_masked_accuracy: 0.9804 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "613/613 [==============================] - 162s 264ms/step - loss: 0.0392 - masked_accuracy: 0.9770 - val_loss: 0.0346 - val_masked_accuracy: 0.9794 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "613/613 [==============================] - 160s 261ms/step - loss: 0.0342 - masked_accuracy: 0.9801 - val_loss: 0.0237 - val_masked_accuracy: 0.9855 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "613/613 [==============================] - 163s 266ms/step - loss: 0.0302 - masked_accuracy: 0.9828 - val_loss: 0.0267 - val_masked_accuracy: 0.9840 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "613/613 [==============================] - 163s 266ms/step - loss: 0.0270 - masked_accuracy: 0.9847 - val_loss: 0.0230 - val_masked_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "613/613 [==============================] - 161s 263ms/step - loss: 0.0241 - masked_accuracy: 0.9866 - val_loss: 0.0230 - val_masked_accuracy: 0.9868 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "613/613 [==============================] - 163s 266ms/step - loss: 0.0221 - masked_accuracy: 0.9879 - val_loss: 0.0207 - val_masked_accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "613/613 [==============================] - 167s 272ms/step - loss: 0.0198 - masked_accuracy: 0.9893 - val_loss: 0.0144 - val_masked_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "613/613 [==============================] - 169s 275ms/step - loss: 0.0182 - masked_accuracy: 0.9902 - val_loss: 0.0238 - val_masked_accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "613/613 [==============================] - 185s 301ms/step - loss: 0.0170 - masked_accuracy: 0.9910 - val_loss: 0.0102 - val_masked_accuracy: 0.9942 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "613/613 [==============================] - 227s 371ms/step - loss: 0.0153 - masked_accuracy: 0.9919 - val_loss: 0.0388 - val_masked_accuracy: 0.9798 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "613/613 [==============================] - 247s 404ms/step - loss: 0.0142 - masked_accuracy: 0.9924 - val_loss: 0.0101 - val_masked_accuracy: 0.9942 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "613/613 [==============================] - 239s 390ms/step - loss: 0.0130 - masked_accuracy: 0.9931 - val_loss: 0.0091 - val_masked_accuracy: 0.9949 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "613/613 [==============================] - 217s 354ms/step - loss: 0.0122 - masked_accuracy: 0.9936 - val_loss: 0.0231 - val_masked_accuracy: 0.9895 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "613/613 [==============================] - 238s 388ms/step - loss: 0.0115 - masked_accuracy: 0.9941 - val_loss: 0.0076 - val_masked_accuracy: 0.9958 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "613/613 [==============================] - 210s 343ms/step - loss: 0.0108 - masked_accuracy: 0.9945 - val_loss: 0.0112 - val_masked_accuracy: 0.9938 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# training set up and model training\n",
    "lr = 0.001\n",
    "weight_decay = 0.01\n",
    "optim = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=\"model/rnn_translator.keras\", monitor='val_loss',\n",
    "                                    saves_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=9, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, min_lr=1e-7, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    #loss=\"sparse_categorical_crossentropy\",\n",
    "    loss=masked_loss,\n",
    "    metrics=[masked_accuracy],\n",
    ")\n",
    "history = model.fit(train_ds,\n",
    "                          epochs=30,\n",
    "                          validation_data=val_ds,\n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa3c5c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "train_loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(len(train_loss))\n",
    "plt.plot(epochs, train_loss, label=\"train_loss\")\n",
    "plt.plot(epochs, val_loss, label=\"validation_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c565fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_txt = [pair[0] for pair in test_pairs]\n",
    "test_target_txt = [pair[1] for pair in test_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a4e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = keras.models.load_model(\"model/rnn_translator.keras\",\n",
    "                               custom_objects={\n",
    "                                         \"masked_loss\": masked_loss,\n",
    "                                         \"masked_accuracy\": masked_accuracy,\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c516f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " source (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " translated (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, None, 16)     880         ['source[0][0]']                 \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, None, 16)     880         ['translated[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 256)         420864      ['embedding_6[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " gru_7 (GRU)                    (None, None, 256)    210432      ['embedding_7[0][0]',            \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, None, 256)    0           ['gru_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, None, 22)     5654        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, 22)     0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 638,710\n",
      "Trainable params: 638,710\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add softmax activation in the output of the model\n",
    "inputs = model.inputs\n",
    "out = model.outputs[0]\n",
    "outputs = layers.Activation(\"softmax\")(out)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c79f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated text generation function\n",
    "class TokenGenerator():\n",
    "    def __init__(self):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def __call__(self):\n",
    "        raise NotImplemented\n",
    "\n",
    "class Generate_tokens(TokenGenerator):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def __call__(self, input_seq, target_vectorization, source_vectorization, model, **kwargs):\n",
    "        max_out_seq_len = kwargs.get(\"max_out_seq_len\", 30)\n",
    "        \n",
    "        out_vocab = target_vectorization.get_vocabulary()\n",
    "        out_index_lookup = dict(zip(range(len(out_vocab)), out_vocab))  # mapping vectorization to vocab\n",
    "        tokenized_input_seq = source_vectorization([input_seq])\n",
    "        decoded_sentence = \"[start]\"\n",
    "        for i in range(max_out_seq_len):\n",
    "            tokenized_out_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
    "            # input: 1st elem for encoder, and 2nd elem for the first self-attention layer in decoder\n",
    "            predictions = model([tokenized_input_seq, tokenized_out_sentence])\n",
    "            predicted_token_index = np.argmax(predictions[0, i, :])  # a token with highest probabillity\n",
    "            predicted_token = out_index_lookup[predicted_token_index]\n",
    "            decoded_sentence += \" \" + predicted_token\n",
    "            if predicted_token == \"[end]\":\n",
    "                break\n",
    "        return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ad6a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Input Text Sequences: 16800\n",
      "Currently at sequence 0, and count: 0\n",
      "Model Tranlsated: [start] b d b d a d d e c e b d b d a h g h i b d a e k b d a h j l m a g f ed a e ee c e a d ef eg [end]\n",
      "Ground-Truth:     [start] b d b d a d d e c e b d b d a h g h i b d a e k b d a h j l m a g f ed a e ee c e a d ef eg [end]\n",
      "Currently at sequence 100, and count: 86\n",
      "Currently at sequence 200, and count: 171\n",
      "Currently at sequence 300, and count: 260\n",
      "Model Tranlsated: [start] c e b d b d b d b d c d b d a f i j a h g h k a h e f l a d d m b d c f a e ef a h ed ee eg [end]\n",
      "Ground-Truth:     [start] c e b d b d b d b d c d b d a d i j a h g h k a h e f l a d d m b d c f a e ef a h ed ee eg [end]\n",
      "Currently at sequence 400, and count: 342\n",
      "Model Tranlsated: [start] c g c f b d b d a f f g a g e h a e i b d a f j k a d d l [end]\n",
      "Ground-Truth:     [start] c g c f b d b d a f f g a g e h a e i b d a f j k a d d l [end]\n",
      "Currently at sequence 500, and count: 433\n",
      "Model Tranlsated: [start] c d c f c e a f e f a d d g b d a f h i a e j [end]\n",
      "Ground-Truth:     [start] c d c f c e a f e f a d d g b d a f h i a e j [end]\n",
      "Currently at sequence 600, and count: 521\n",
      "Currently at sequence 700, and count: 609\n",
      "Model Tranlsated: [start] b d b d b d c g a h e f g a e h a d d i c e c g a h j k l b d a g m ed [end]\n",
      "Ground-Truth:     [start] b d b d b d c g a h e f g a e h a d d i c e c g a h j k l b d a g m ed [end]\n",
      "Currently at sequence 800, and count: 693\n",
      "Model Tranlsated: [start] c g b d b d b d a f f g b d a g h i b d a g j k c e c g c f a h m ed ee a g l ef a h d e eg a e eh [end]\n",
      "Ground-Truth:     [start] c g b d b d b d a f f g b d a f h i b d a g j k c e c g c f a h m ed ee a g l ef a h d e eg a e eh [end]\n",
      "Currently at sequence 900, and count: 779\n",
      "Currently at sequence 1000, and count: 860\n",
      "Currently at sequence 1100, and count: 944\n",
      "Currently at sequence 1200, and count: 1033\n",
      "Currently at sequence 1300, and count: 1123\n",
      "Model Tranlsated: [start] b d c e c f c f a g f g b d a d h i a d e j a d d k [end]\n",
      "Ground-Truth:     [start] b d c e c f c f a g f g b d a d h i a d e j a d d k [end]\n",
      "Model Tranlsated: [start] b d c d c e b d a g f g a f e h a f d i b d b d a f k l c g a h j m ed [end]\n",
      "Ground-Truth:     [start] b d c d c e b d a g f g a f e h a f d i b d b d a f k l c g a h j m ed [end]\n",
      "Currently at sequence 1400, and count: 1208\n",
      "Currently at sequence 1500, and count: 1296\n",
      "Currently at sequence 1600, and count: 1385\n",
      "Currently at sequence 1700, and count: 1466\n",
      "Model Tranlsated: [start] b d c g c g a f e f a g d g c g a g h i a e j [end]\n",
      "Ground-Truth:     [start] b d c g c g a f e f a g d g c g a g h i a e j [end]\n",
      "Model Tranlsated: [start] c d c g b d c f a e g a g f h c d a f i j a h d e k [end]\n",
      "Ground-Truth:     [start] c d c g b d c f a e g a g f h c d a f i j a h d e k [end]\n",
      "Currently at sequence 1800, and count: 1552\n",
      "Model Tranlsated: [start] c f c f b d c d b d a g g h a f f i a g e j a e k a f d l [end]\n",
      "Ground-Truth:     [start] c f c f b d c d b d a g g h a f f i a g e j a e k a f d l [end]\n",
      "Currently at sequence 1900, and count: 1639\n",
      "Model Tranlsated: [start] c g c g c f b d a f f g a h d e h b d c f a h i j k [end]\n",
      "Ground-Truth:     [start] c g c g c f b d a f f g a h d e h b d c f a h i j k [end]\n",
      "Currently at sequence 2000, and count: 1723\n",
      "Currently at sequence 2100, and count: 1811\n",
      "Currently at sequence 2200, and count: 1896\n",
      "Currently at sequence 2300, and count: 1976\n",
      "Currently at sequence 2400, and count: 2066\n",
      "Currently at sequence 2500, and count: 2150\n",
      "Currently at sequence 2600, and count: 2231\n",
      "Model Tranlsated: [start] c g a e d b d b d c f a d g h c f a g i j a g f k b d a h e l m b d a f ed ee c e a d ef eg [end]\n",
      "Ground-Truth:     [start] c g a e d b d b d c f a d g h c f a g i j a f f k b d a h e l m b d a f ed ee c e a d ef eg [end]\n",
      "Currently at sequence 2700, and count: 2312\n",
      "Model Tranlsated: [start] c f c d b d a f e f b d a g g h b d a h d i j [end]\n",
      "Ground-Truth:     [start] c f c d b d a f e f b d a g g h b d a h d i j [end]\n",
      "Currently at sequence 2800, and count: 2397\n",
      "Currently at sequence 2900, and count: 2484\n",
      "Model Tranlsated: [start] c d b d a g d e a e f b d b d a d h i a g g j [end]\n",
      "Ground-Truth:     [start] c d b d a g d e a e f b d b d a d h i a g g j [end]\n",
      "Model Tranlsated: [start] c f b d b d a d e f b d a d g h a g d i b d a g j k a e l [end]\n",
      "Ground-Truth:     [start] c f b d b d a d e f b d a d g h a g d i b d a g j k a e l [end]\n",
      "Currently at sequence 3000, and count: 2569\n",
      "Model Tranlsated: [start] c f c g a g d e c f c d a h f g h b d c f a h i j k a e l [end]\n",
      "Ground-Truth:     [start] c f c g a g d e c f c d a h f g h b d c f a h i j k a e l [end]\n",
      "Model Tranlsated: [start] b d c d b d c d a d f g a f e h b d a f i j c d a h d k l [end]\n",
      "Ground-Truth:     [start] b d c d b d c d a d f g a f e h b d a f i j c d a h d k l [end]\n",
      "Currently at sequence 3100, and count: 2656\n",
      "Currently at sequence 3200, and count: 2742\n",
      "Currently at sequence 3300, and count: 2832\n",
      "Model Tranlsated: [start] b d c g b d b d a h e f g c f a f h i c g c f a f k l a h d j m [end]\n",
      "Ground-Truth:     [start] b d c g b d b d a h e f g c f a f h i c g c f a f k l a h d j m [end]\n",
      "Currently at sequence 3400, and count: 2918\n",
      "Model Tranlsated: [start] b d c g a e e b d c g a d g h a d f i a f d j [end]\n",
      "Ground-Truth:     [start] b d c g a e e b d c g a d g h a d f i a f d j [end]\n",
      "Currently at sequence 3500, and count: 2992\n",
      "Currently at sequence 3600, and count: 3074\n",
      "Model Tranlsated: [start] c d b d c g b d a f f g a g e h c d b d c d a d k l a g j m a h d i ed [end]\n",
      "Ground-Truth:     [start] c d b d c g b d a f f g a g e h c d b d c d a d k l a g j m a h d i ed [end]\n",
      "Currently at sequence 3700, and count: 3156\n",
      "Currently at sequence 3800, and count: 3242\n",
      "Model Tranlsated: [start] b d c e a e e b d b d a g g h a h d f i b d b d a h j k l b d b d a g ed ee a g m ef [end]\n",
      "Ground-Truth:     [start] b d c e a e e b d b d a g g h a h d f i b d b d a h j k l b d b d a g ed ee a g m ef [end]\n",
      "Currently at sequence 3900, and count: 3325\n",
      "Currently at sequence 4000, and count: 3410\n",
      "Currently at sequence 4100, and count: 3498\n",
      "Model Tranlsated: [start] c f a e d b d b d c f a h f g h a g e i a e j [end]\n",
      "Ground-Truth:     [start] c f a e d b d b d c f a h f g h a g e i a e j [end]\n",
      "Currently at sequence 4200, and count: 3581\n",
      "Currently at sequence 4300, and count: 3656\n",
      "Currently at sequence 4400, and count: 3745\n",
      "Currently at sequence 4500, and count: 3831\n",
      "Currently at sequence 4600, and count: 3911\n",
      "Model Tranlsated: [start] b d c f b d a g e f c g c e b d a g i j a f h k c e b d a d m ed a f l ee a g g ef c g a h d eg eh [end]\n",
      "Ground-Truth:     [start] b d c f b d a g e f c g b d c e a g i j a f h k c e b d a d m ed a f l ee a g g ef c g a h d eg eh [end]\n",
      "Model Tranlsated: [start] b d c f a e e b d c g a f g h c d a g i j a d f k b d b d b d a d ed ee a h l m ef a f d eg [end]\n",
      "Ground-Truth:     [start] b d c f a e e b d c g a f g h c d a g i j a d f k b d b d b d a d ed ee a h l m ef a f d eg [end]\n",
      "Currently at sequence 4700, and count: 3991\n",
      "Currently at sequence 4800, and count: 4077\n",
      "Model Tranlsated: [start] c f c g c d c g b d a g g h a h e f i a e j b d c f a g l m a g k ed a g d ee b d a d ef eg [end]\n",
      "Ground-Truth:     [start] c f c g c d c g b d a g g h a h e f i a e j b d c f a g l m a g k ed a g d ee b d a d ef eg [end]\n",
      "Currently at sequence 4900, and count: 4163\n",
      "Currently at sequence 5000, and count: 4245\n",
      "Currently at sequence 5100, and count: 4336\n",
      "Currently at sequence 5200, and count: 4421\n",
      "Currently at sequence 5300, and count: 4508\n",
      "Model Tranlsated: [start] c g c d b d a e f a e g c e a e i a h e h j a f d k [end]\n",
      "Ground-Truth:     [start] c g c d b d a e f a e g c e a e i a h e h j a f d k [end]\n",
      "Currently at sequence 5400, and count: 4601\n",
      "Model Tranlsated: [start] b d c d b d a e f b d c g b d a d i j c d a e l a h h k m a d g ed a h d e ee [end]\n",
      "Ground-Truth:     [start] b d c d b d a e f b d c g b d a d i j c d a e l a h h k m a d g ed a h d e ee [end]\n",
      "Currently at sequence 5500, and count: 4688\n",
      "Model Tranlsated: [start] c g b d c g c d c f a f g h a h e f i b d c d a f k l a d j m a g d ed [end]\n",
      "Ground-Truth:     [start] c g b d c g c d c d a f g h a h e f i b d c f a f k l a d j m a g d ed [end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at sequence 5600, and count: 4777\n",
      "Model Tranlsated: [start] c d c e c e a d e f b d c f a d h i a e j a g g k a d d l c d c f a h m ed ee [end]\n",
      "Ground-Truth:     [start] c d c e c e a d e f b d c f a d h i a e j a g g k a d d l c d c d a h m ed ee [end]\n",
      "Currently at sequence 5700, and count: 4865\n",
      "Currently at sequence 5800, and count: 4955\n",
      "Currently at sequence 5900, and count: 5041\n",
      "Model Tranlsated: [start] b d c e c e c e a f f g c f a d h i a h d e j [end]\n",
      "Ground-Truth:     [start] b d c e c e c e a f f g c f a d h i a h d e j [end]\n",
      "Currently at sequence 6000, and count: 5123\n",
      "Currently at sequence 6100, and count: 5210\n",
      "Model Tranlsated: [start] c d b d c d a e f c d a g g h a h d e i c f a g j k [end]\n",
      "Ground-Truth:     [start] c d b d c d a e f c d a g g h a h d e i c f a g j k [end]\n",
      "Currently at sequence 6200, and count: 5293\n",
      "Currently at sequence 6300, and count: 5377\n",
      "Currently at sequence 6400, and count: 5459\n",
      "Currently at sequence 6500, and count: 5543\n",
      "Model Tranlsated: [start] c e b d c g b d a h e f g b d a g h i a f d j b d a g k l [end]\n",
      "Ground-Truth:     [start] c e b d c g b d a h e f g b d a g h i a f d j b d a g k l [end]\n",
      "Currently at sequence 6600, and count: 5626\n",
      "Model Tranlsated: [start] c f c d b d b d a h e f g b d c g a d i j b d a g k l c g a h h m ed a e ee a f d ef [end]\n",
      "Ground-Truth:     [start] c f c d b d b d a h e f g b d c g a d i j b d a g k l c g a h h m ed a e ee a f d ef [end]\n",
      "Model Tranlsated: [start] c g b d a d d e c d a f f g c d b d a e j a e k a g i l c e a g m ed c e b d a h ee ef eg a g h eh [end]\n",
      "Ground-Truth:     [start] c g b d a d d e c d a f f g c d b d a e j a e k a g i l c e c e a h m ed ee b d a g ef eg a f h eh [end]\n",
      "Currently at sequence 6700, and count: 5710\n",
      "Model Tranlsated: [start] c e b d b d a e f a h d e g c g c e a h h i j [end]\n",
      "Ground-Truth:     [start] c e b d b d a e f a h d e g c g c e a h h i j [end]\n",
      "Currently at sequence 6800, and count: 5798\n",
      "Model Tranlsated: [start] c e b d a g d e c f a g f g a e h b d a f i j [end]\n",
      "Ground-Truth:     [start] c e b d a g d e c f a g f g a e h b d a f i j [end]\n",
      "Currently at sequence 6900, and count: 5884\n",
      "Currently at sequence 7000, and count: 5971\n",
      "Currently at sequence 7100, and count: 6059\n",
      "Currently at sequence 7200, and count: 6144\n",
      "Currently at sequence 7300, and count: 6230\n",
      "Model Tranlsated: [start] c d c g c d a f e f a g d g b d c g a f i j a e k b d a g l m a e ed a g h ee b d a g ef eg [end]\n",
      "Ground-Truth:     [start] c d c g c d a f e f a g d g b d c g a f i j a e k b d a g l m a e ed a g h ee b d a g ef eg [end]\n",
      "Currently at sequence 7400, and count: 6316\n",
      "Currently at sequence 7500, and count: 6405\n",
      "Currently at sequence 7600, and count: 6492\n",
      "Model Tranlsated: [start] c d b d b d c g c d b d a g h i a h f g j a g e k a f d l [end]\n",
      "Ground-Truth:     [start] c d b d b d c g c d b d a g h i a h f g j a g e k a f d l [end]\n",
      "Currently at sequence 7700, and count: 6571\n",
      "Model Tranlsated: [start] c g b d c d a e f a g e g a g d h a e i b d a g j k [end]\n",
      "Ground-Truth:     [start] c g b d c d a e f a g e g a g d h a e i b d a g j k [end]\n",
      "Model Tranlsated: [start] b d b d c g a f e f c f b d a g h i a h d g j [end]\n",
      "Ground-Truth:     [start] b d b d c g a f e f c f b d a g h i a h d g j [end]\n",
      "Currently at sequence 7800, and count: 6660\n",
      "Model Tranlsated: [start] c f c e b d a g e f b d a h d g h c f a d i j [end]\n",
      "Ground-Truth:     [start] c f c e b d a g e f b d a h d g h c f a d i j [end]\n",
      "Currently at sequence 7900, and count: 6740\n",
      "Currently at sequence 8000, and count: 6825\n",
      "Model Tranlsated: [start] c d b d b d b d a f f g b d a h e h i b d a h d j k [end]\n",
      "Ground-Truth:     [start] c d b d b d b d a f f g b d a h e h i b d a h d j k [end]\n",
      "Currently at sequence 8100, and count: 6912\n",
      "Model Tranlsated: [start] b d c f c e b d b d b d a h g h i c d a g j k a g f l a h d e m c f a d ed ee [end]\n",
      "Ground-Truth:     [start] b d c f c e b d b d b d a h g h i c d a g j k a g f l a h d e m c f a d ed ee [end]\n",
      "Model Tranlsated: [start] c g c e a f d e b d b d c f a g h i c f a f j k c g a d l m a f g ed a d f ee [end]\n",
      "Ground-Truth:     [start] c g c e a f d e b d b d c f a g h i c f a f j k c g a d l m a f g ed a d f ee [end]\n",
      "Model Tranlsated: [start] c d b d b d c f a d f g a h d e h c g c f a f j k a g i l [end]\n",
      "Ground-Truth:     [start] c d b d b d c f a d f g a h d e h c g c f a f j k a g i l [end]\n",
      "Currently at sequence 8200, and count: 6998\n",
      "Currently at sequence 8300, and count: 7085\n",
      "Currently at sequence 8400, and count: 7174\n",
      "Currently at sequence 8500, and count: 7260\n",
      "Model Tranlsated: [start] b d b d b d c e a g f g a e h c e a g i j a f e k a g d l [end]\n",
      "Ground-Truth:     [start] b d b d b d c e a g f g a e h c e a g i j a f e k a g d l [end]\n",
      "Model Tranlsated: [start] c g c f a g d e b d a g f g c e c g a g i j b d b d c g a h l m ed c g a h k ee ef a d h eg [end]\n",
      "Ground-Truth:     [start] c g c f a g d e b d a g f g c e c g a g i j b d b d c g a h l m ed c f a h k ee ef c g a h h eg eh [end]\n",
      "Model Tranlsated: [start] b d c f c f b d c d a h f g h a h d e i a e j b d a d k l [end]\n",
      "Ground-Truth:     [start] b d c f c f b d c d a h f g h a h d e i a e j b d a d k l [end]\n",
      "Currently at sequence 8600, and count: 7346\n",
      "Currently at sequence 8700, and count: 7428\n",
      "Model Tranlsated: [start] b d b d c e b d b d a h f g h b d a d i j a h d e k [end]\n",
      "Ground-Truth:     [start] b d b d c e b d b d a h f g h b d a d i j a h d e k [end]\n",
      "Currently at sequence 8800, and count: 7513\n",
      "Currently at sequence 8900, and count: 7600\n",
      "Currently at sequence 9000, and count: 7688\n",
      "Model Tranlsated: [start] c f b d c g b d a f f g c d a d h i a f e j c g a d k l a f d m [end]\n",
      "Ground-Truth:     [start] c f b d c g b d a f f g c d a d h i a f e j c g a d k l a f d m [end]\n",
      "Currently at sequence 9100, and count: 7783\n",
      "Currently at sequence 9200, and count: 7863\n",
      "Model Tranlsated: [start] c f b d b d b d a d f g a d e h a d d i c f a e k a f j l [end]\n",
      "Ground-Truth:     [start] c f b d b d b d a d f g a d e h a d d i c f a e k a f j l [end]\n",
      "Currently at sequence 9300, and count: 7950\n",
      "Model Tranlsated: [start] b d c d c e b d a h e f g b d a h d h i b d b d a h j k l c f a d m ed c d a d ee ef b d a f eg eh [end]\n",
      "Ground-Truth:     [start] b d c d c e b d a h e f g b d a h d h i b d b d a h j k l c f a d m ed c d a d ee ef b d a f eg eh [end]\n",
      "Currently at sequence 9400, and count: 8030\n",
      "Model Tranlsated: [start] c g c g c g c g c d a f g h c f a d i j a h e f k b d a h d l m b d a g ed ee [end]\n",
      "Ground-Truth:     [start] c g c g c g c g c d a f g h c f a d i j a h e f k b d a h d l m b d a g ed ee [end]\n",
      "Currently at sequence 9500, and count: 8121\n",
      "Currently at sequence 9600, and count: 8204\n",
      "Currently at sequence 9700, and count: 8290\n",
      "Currently at sequence 9800, and count: 8380\n",
      "Currently at sequence 9900, and count: 8468\n",
      "Currently at sequence 10000, and count: 8552\n",
      "Model Tranlsated: [start] c f c f a e e a e f b d a f g h b d a e j a h d i k c g b d a d m ed c g c d a h ee ef eg a f l eh [end]\n",
      "Ground-Truth:     [start] c f c f a e e a e f b d a f g h a f d i b d c g a d k l b d a h j m ed c g c d a g ef eg a f ee eh [end]\n",
      "Currently at sequence 10100, and count: 8637\n",
      "Currently at sequence 10200, and count: 8720\n",
      "Model Tranlsated: [start] c g a e d c g a g e f c e c d a f h i b d b d a h j k l a d g m [end]\n",
      "Ground-Truth:     [start] c g a e d c g a g e f c e c d a f h i b d b d a h j k l a d g m [end]\n",
      "Currently at sequence 10300, and count: 8808\n",
      "Model Tranlsated: [start] c f b d b d a e f c f a d g h a h d e i b d a e k b d c f a d m ed a h j l ee [end]\n",
      "Ground-Truth:     [start] c f b d b d a e f c f a d g h a h d e i b d a e k b d c f a d m ed a h j l ee [end]\n",
      "Model Tranlsated: [start] c e a e d c f a g e f c e a g g h b d a d i j b d c e a f l m b d a f ed ee a g k ef [end]\n",
      "Ground-Truth:     [start] c e a e d c f a g e f c e a g g h b d a d i j b d c e a f l m b d a f ed ee a g k ef [end]\n",
      "Model Tranlsated: [start] c e c g a f d e c e c e b d c g a h h i j a h f g k c f c e a d m ed a d l ee a e ef [end]\n",
      "Ground-Truth:     [start] c e c g a f d e c e c e b d c g a h h i j a h f g k c f c e a d m ed a d l ee b d a g ef eg [end]\n",
      "Currently at sequence 10400, and count: 8894\n",
      "Model Tranlsated: [start] c f b d c f a d e f a g d g b d b d a h h i j [end]\n",
      "Ground-Truth:     [start] c f b d c f a d e f a g d g b d b d a h h i j [end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tranlsated: [start] c f b d c d a f e f a d d g b d c d b d a e k a f j l a h h i m b d a g ed ee [end]\n",
      "Ground-Truth:     [start] c f b d c d a f e f a d d g b d c d b d a e k a f j l a h h i m b d a g ed ee [end]\n",
      "Currently at sequence 10500, and count: 8980\n",
      "Model Tranlsated: [start] b d c g a f d e b d b d c d c e a g i j a d h k a g g l a e m a f f ed [end]\n",
      "Ground-Truth:     [start] b d c g a f d e b d b d c d c e a g i j a d h k a g g l a e m a f f ed [end]\n",
      "Model Tranlsated: [start] c e b d a d d e c e a d f g a e h b d c e a h i j k [end]\n",
      "Ground-Truth:     [start] c e b d a d d e c e a d f g a e h b d c e a h i j k [end]\n",
      "Model Tranlsated: [start] c g c d c d a e f c d a h e g h b d a g i j a f d k [end]\n",
      "Ground-Truth:     [start] c g c d c d a e f c d a h e g h b d a g i j a f d k [end]\n",
      "Model Tranlsated: [start] b d b d c g a h d e f a e g b d a e i b d c d a g k l a d j m a f h ed [end]\n",
      "Ground-Truth:     [start] b d b d c g a h d e f a e g b d a e i b d c d a g k l a d j m a f h ed [end]\n",
      "Currently at sequence 10600, and count: 9067\n",
      "Currently at sequence 10700, and count: 9152\n",
      "Model Tranlsated: [start] c d a e d a e e c f c d a d g h b d a h f i j [end]\n",
      "Ground-Truth:     [start] c d a e d a e e c f c d a d g h b d a h f i j [end]\n",
      "Model Tranlsated: [start] c f c f c f c g a e g a f f h a h d e i b d a d j k c d a d l m b d a f ed ee [end]\n",
      "Ground-Truth:     [start] c f c f c f c g a e g a f f h a h d e i b d a d j k c d a d l m b d a f ed ee [end]\n",
      "Currently at sequence 10800, and count: 9237\n",
      "Currently at sequence 10900, and count: 9321\n",
      "Currently at sequence 11000, and count: 9406\n",
      "Model Tranlsated: [start] b d c f a f d e c f b d b d b d c d a h i j k a g h l c g a h g m ed a f f ee [end]\n",
      "Ground-Truth:     [start] b d c f a f d e c f b d b d b d c d a h i j k a f h l c g a h g m ed a f f ee [end]\n",
      "Currently at sequence 11100, and count: 9492\n",
      "Model Tranlsated: [start] b d b d c f b d a h e f g c d a d h i a e j a g d k [end]\n",
      "Ground-Truth:     [start] b d b d c f b d a h e f g c d a d h i a e j a g d k [end]\n",
      "Model Tranlsated: [start] b d b d c f a f e f a e g a f d h c g c e a h i j k [end]\n",
      "Ground-Truth:     [start] b d b d c f a f e f a e g a f d h c g c e a h i j k [end]\n",
      "Currently at sequence 11200, and count: 9580\n",
      "Currently at sequence 11300, and count: 9665\n",
      "Currently at sequence 11400, and count: 9752\n",
      "Currently at sequence 11500, and count: 9838\n",
      "Model Tranlsated: [start] c d c e b d b d c g a g g h c g a d i j c d a h f k l a g e m a d d ed a e ee [end]\n",
      "Ground-Truth:     [start] c d c e b d b d c g a g g h c g a d i j c d a h f k l a g e m a d d ed a e ee [end]\n",
      "Model Tranlsated: [start] b d c f a f d e b d c g a d g h a d f i a e j [end]\n",
      "Ground-Truth:     [start] b d c f a f d e b d c g a d g h a d f i a e j [end]\n",
      "Currently at sequence 11600, and count: 9927\n",
      "Currently at sequence 11700, and count: 10013\n",
      "Model Tranlsated: [start] c f b d a f d e c g c f a f g h c e c d a f j k a e l a g i m c e a h f ed ee [end]\n",
      "Ground-Truth:     [start] c f b d a f d e c g c f a f g h c e c d a f j k a e l a g i m c e a h f ed ee [end]\n",
      "Model Tranlsated: [start] b d b d c e c d a g f g a f e h a d d i a e j b d a f k l c f a g m ed [end]\n",
      "Ground-Truth:     [start] b d b d c e c d a g f g a e h a h d e i a e j b d a f k l c f a g m ed [end]\n",
      "Currently at sequence 11800, and count: 10100\n",
      "Model Tranlsated: [start] b d c e a d d e b d b d b d a g h i a g g j a f f k [end]\n",
      "Ground-Truth:     [start] b d c e a d d e b d b d b d a g h i a g g j a f f k [end]\n",
      "Currently at sequence 11900, and count: 10184\n",
      "Currently at sequence 12000, and count: 10270\n",
      "Model Tranlsated: [start] b d c g b d a h d e f c g c f b d a e j a f i k a f h l a e m a d g ed [end]\n",
      "Ground-Truth:     [start] b d c g b d a h d e f c g c f b d a e j a f i k a f h l a e m a d g ed [end]\n",
      "Model Tranlsated: [start] c d b d b d a g e f a d d g b d c f c d c e a g k l a f j m a d i ed a d h ee [end]\n",
      "Ground-Truth:     [start] c d b d b d a g e f a d d g b d c f c d c e a g k l a f j m a d i ed a d h ee [end]\n",
      "Model Tranlsated: [start] b d c e b d c g a g f g a h d e h c g a f i j [end]\n",
      "Ground-Truth:     [start] b d c e b d c g a g f g a h d e h c g a f i j [end]\n",
      "Currently at sequence 12100, and count: 10359\n",
      "Currently at sequence 12200, and count: 10446\n",
      "Currently at sequence 12300, and count: 10530\n",
      "Model Tranlsated: [start] c f b d b d a h d e f c e a g g h c d a d i j [end]\n",
      "Ground-Truth:     [start] c f b d b d a h d e f c e a g g h c d a d i j [end]\n",
      "Model Tranlsated: [start] c f a e d b d c f c e a d g h b d a h f i j c f b d a h k l m b d a e ee a h e ed ef [end]\n",
      "Ground-Truth:     [start] c f a e d b d c f c e a d g h b d a h f i j c f b d a h k l m b d a e ee a h e ed ef [end]\n",
      "Model Tranlsated: [start] b d b d b d c g c d a h f g h a f e i c f a h d j k [end]\n",
      "Ground-Truth:     [start] b d b d b d c g c d a h f g h a f e i c f a h d j k [end]\n",
      "Currently at sequence 12400, and count: 10616\n",
      "Currently at sequence 12500, and count: 10704\n",
      "Currently at sequence 12600, and count: 10790\n",
      "Currently at sequence 12700, and count: 10876\n",
      "Model Tranlsated: [start] b d c d b d a g e f c e a e h a h d g i b d a d j k [end]\n",
      "Ground-Truth:     [start] b d c d b d a g e f c e a e h a h d g i b d a d j k [end]\n",
      "Model Tranlsated: [start] c d c f b d b d a f f g a h d e h c d a f i j [end]\n",
      "Ground-Truth:     [start] c d c f b d b d a f f g a h d e h c d a f i j [end]\n",
      "Currently at sequence 12800, and count: 10960\n",
      "Currently at sequence 12900, and count: 11037\n",
      "Currently at sequence 13000, and count: 11119\n",
      "Currently at sequence 13100, and count: 11209\n",
      "Currently at sequence 13200, and count: 11300\n",
      "Model Tranlsated: [start] b d a e d b d b d b d a g g h a d f i b d a d j k c e a h e l m [end]\n",
      "Ground-Truth:     [start] b d a e d b d b d b d a g g h a d f i b d a d j k c e a h e l m [end]\n",
      "Currently at sequence 13300, and count: 11390\n",
      "Currently at sequence 13400, and count: 11478\n",
      "Currently at sequence 13500, and count: 11561\n",
      "Model Tranlsated: [start] b d b d b d b d c g a f g h a d f i a g e j a d d k [end]\n",
      "Ground-Truth:     [start] b d b d b d b d c g a f g h a d f i a g e j a d d k [end]\n",
      "Currently at sequence 13600, and count: 11651\n",
      "Currently at sequence 13700, and count: 11739\n",
      "Model Tranlsated: [start] b d b d a d d e c f a f f g c d a d h i b d b d a d k l b d a h j m ed b d a f ee ef c f a g eg eh [end]\n",
      "Ground-Truth:     [start] b d b d a d d e c f a f f g c d a d h i b d b d a d k l b d a h j m ed b d a f ee ef c f a g eg eh [end]\n",
      "Model Tranlsated: [start] c e c g c f c d a e g a h e f h b d a f i j a g d k a e l [end]\n",
      "Ground-Truth:     [start] c e c g c f c d a e g a h e f h b d a f i j a g d k a e l [end]\n",
      "Currently at sequence 13800, and count: 11826\n",
      "Currently at sequence 13900, and count: 11914\n",
      "Model Tranlsated: [start] c g a e d c d c d b d a d g h a h e f i a e j b d a g k l [end]\n",
      "Ground-Truth:     [start] c g a e d c d c d b d a d g h a h e f i a e j b d a g k l [end]\n",
      "Model Tranlsated: [start] b d c f c e a g e f b d a d g h c g a g i j a f d k b d a d l m [end]\n",
      "Ground-Truth:     [start] b d c f c e a g e f b d a d g h c g a g i j a f d k b d a d l m [end]\n",
      "Currently at sequence 14000, and count: 11995\n",
      "Currently at sequence 14100, and count: 12085\n",
      "Model Tranlsated: [start] c e c g c e a d e f b d a d g h a f d i a e j [end]\n",
      "Ground-Truth:     [start] c e c g c e a d e f b d a d g h a f d i a e j [end]\n",
      "Currently at sequence 14200, and count: 12168\n",
      "Model Tranlsated: [start] b d b d b d a g e f c d b d a e i a h g h j c g a d k l c e c f a h m ed ee b d a h d ef eg [end]\n",
      "Ground-Truth:     [start] b d b d b d a g e f c d b d a e i a h g h j c g a d k l c d c e a h m ed ee b d a h d ef eg [end]\n",
      "Currently at sequence 14300, and count: 12251\n",
      "Currently at sequence 14400, and count: 12337\n",
      "Model Tranlsated: [start] c g b d c g b d b d a f g h a d f i a d e j a d d k [end]\n",
      "Ground-Truth:     [start] c g b d c g b d b d a f g h a d f i a d e j a d d k [end]\n",
      "Model Tranlsated: [start] b d c d a e e b d b d a d g h a g f i a g d j c g c f a h k l m c d a d ed ee [end]\n",
      "Ground-Truth:     [start] b d c d a e e b d b d a d g h a g f i a g d j c g c f a h k l m c d a d ed ee [end]\n",
      "Currently at sequence 14500, and count: 12421\n",
      "Currently at sequence 14600, and count: 12513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tranlsated: [start] b d a e d c e c g a h e f g b d a e i b d a e k a g j l a d h m b d a d ed ee [end]\n",
      "Ground-Truth:     [start] b d a e d c e c g a h e f g b d a e i b d a e k a g j l a d h m b d a d ed ee [end]\n",
      "Model Tranlsated: [start] c d c e a g d e a e f b d a f g h c e b d b d a d k l b d a h j m ed a g i ee [end]\n",
      "Ground-Truth:     [start] c d c e a g d e a e f b d a f g h c e b d b d a d k l b d a h j m ed a g i ee [end]\n",
      "Model Tranlsated: [start] b d a e d b d b d b d a d g h b d c e a g j k a d i l c e a h f m ed a f e ee [end]\n",
      "Ground-Truth:     [start] b d a e d b d b d b d a d g h b d c e a g j k a d i l c e a h f m ed a f e ee [end]\n",
      "Currently at sequence 14700, and count: 12598\n",
      "Currently at sequence 14800, and count: 12682\n",
      "Currently at sequence 14900, and count: 12769\n",
      "Currently at sequence 15000, and count: 12860\n",
      "Currently at sequence 15100, and count: 12948\n",
      "Currently at sequence 15200, and count: 13034\n",
      "Currently at sequence 15300, and count: 13120\n",
      "Currently at sequence 15400, and count: 13202\n",
      "Currently at sequence 15500, and count: 13289\n",
      "Model Tranlsated: [start] b d c g c g a e f b d a h e g h c f a g i j a f d k b d a e m a d l ed [end]\n",
      "Ground-Truth:     [start] b d c g c g a e f b d a h e g h c f a g i j a f d k b d a e m a d l ed [end]\n",
      "Currently at sequence 15600, and count: 13381\n",
      "Currently at sequence 15700, and count: 13463\n",
      "Currently at sequence 15800, and count: 13548\n",
      "Currently at sequence 15900, and count: 13633\n",
      "Model Tranlsated: [start] b d b d b d b d c e a g g h a e i a h e f j a f d k b d a f l m [end]\n",
      "Ground-Truth:     [start] b d b d b d b d c e a g g h a e i a h e f j a f d k b d a f l m [end]\n",
      "Currently at sequence 16000, and count: 13721\n",
      "Model Tranlsated: [start] b d b d c f a d e f c g a f g h c e a e j a h d i k [end]\n",
      "Ground-Truth:     [start] b d b d c f a d e f c g a f g h c e a e j a h d i k [end]\n",
      "Currently at sequence 16100, and count: 13806\n",
      "Model Tranlsated: [start] b d b d a d d e c g a f f g b d a f h i c d a e k a d j l b d a g m ed [end]\n",
      "Ground-Truth:     [start] b d b d a d d e c g a f f g b d a f h i c d a e k a d j l b d a g m ed [end]\n",
      "Currently at sequence 16200, and count: 13895\n",
      "Currently at sequence 16300, and count: 13982\n",
      "Currently at sequence 16400, and count: 14069\n",
      "Currently at sequence 16500, and count: 14151\n",
      "Currently at sequence 16600, and count: 14243\n",
      "Currently at sequence 16700, and count: 14326\n"
     ]
    }
   ],
   "source": [
    "# translate the source language to target language using our best model\n",
    "token_gen = Generate_tokens()\n",
    "translated_texts = []\n",
    "print(f\"Total Number of Input Text Sequences: {len(test_input_txt)}\")\n",
    "correct_count = 0\n",
    "rand_idx = np.random.randint(0, high=len(test_input_txt)-1, size=100)\n",
    "for i in range(len(test_input_txt)):\n",
    "    if i % 100 == 0: print(f\"Currently at sequence {i}, and count: {correct_count}\")\n",
    "    translated_seq = token_gen(test_input_txt[i], target_vectorization,\n",
    "                    source_vectorization, model=model, max_out_seq_len=output_seq_len)\n",
    "    if i in rand_idx:\n",
    "        print(f\"Model Tranlsated: {translated_seq}\")\n",
    "        print(f\"Ground-Truth:     {test_target_txt[i]}\")\n",
    "    if translated_seq == test_target_txt[i]:\n",
    "        correct_count += 1\n",
    "    translated_texts.append(translated_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fa8bcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8576190476190476\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Accuracy: {correct_count / len(translated_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00fe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
